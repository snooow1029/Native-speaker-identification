{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import gradio as gr\n",
    "import random\n",
    "import re\n",
    "\n",
    "from integrated_gradient import load_models, attribution_score, get_smooth_framewise_error, get_feature, evaluate\n",
    "from utils import get_sentences, get_pronunciation, get_target_words, get_padded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_db = [\"model\", \"algorithm\", \"data\", \"feature\", \"training\", \"loss\", \"accuracy\", \"classification\", \"regression\", \"network\"]\n",
    "init_examples = [\"None\"]\n",
    "target_sentence = \"This was a curious coincidence.\"\n",
    "target_words = get_target_words(target_sentence)\n",
    "practice_word = \"\"\n",
    "\n",
    "whisper_model = whisper.load_model(\"tiny.en\")\n",
    "upstream_model, downstream_model, device = load_models(isWav= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio(audio_path):\n",
    "    result = whisper_model.transcribe(audio_path, word_timestamps=True)\n",
    "    words = [w for seg in result[\"segments\"] for w in seg[\"words\"]]\n",
    "    transcribed_words = [re.sub(r'[^\\w]', '', w[\"word\"]) for w in words]\n",
    "    print(f'''Target: {target_words}\\nTranscribed: {transcribed_words}\n",
    "        ''')\n",
    "    if len(transcribed_words) != len(target_words):\n",
    "        print(f'''\n",
    "            Mismatch between transcribed words length and target sentence\n",
    "            Target: {len(target_words)}\n",
    "            Transcribed: {len(words)}\n",
    "        ''')\n",
    "        target_words, transcribed_words = get_padded_words(target_words, transcribed_words)\n",
    "    \n",
    "    tokens = []\n",
    "    missed_words = []\n",
    "    for i, w in enumerate(words):\n",
    "        target_word = target_words[i]\n",
    "        transcribed_word = transcribed_words[i]\n",
    "        if transcribed_word.lower() != target_word.lower():\n",
    "            tokens.append((target_word, 'Target'))\n",
    "            tokens.append((transcribed_word, 'Transcribed'))\n",
    "            missed_words.append(target_word.lower())\n",
    "        else:\n",
    "            tokens.append((transcribed_word, None))\n",
    "        tokens.append((\" \",None))\n",
    "    \n",
    "    print(\"transcribe result:\", result)\n",
    "    yield tokens, gr.Dataset(samples=[[s] for s in []])\n",
    "    \n",
    "    feature = get_feature(audio_path, upstream_model, device, isWav = True)\n",
    "    predicted, _ = evaluate(downstream_model, feature, device)\n",
    "    \n",
    "    if predicted == 1:\n",
    "        feedback = 'Your pronunciation is very accurate, and you are recognized as a native speaker!'\n",
    "        yield ((w, None) for w in feedback), gr.Dataset(samples=[[s] for s in missed_words])\n",
    "    else:\n",
    "    \n",
    "        attributions, _ = attribution_score(feature, downstream_model)\n",
    "        frame_errors, peaks = get_smooth_framewise_error(attributions)\n",
    "        print(f\"frame_errors len: {len(frame_errors)}\")\n",
    "\n",
    "        bad_s = peaks*0.02\n",
    "        print(\"bad_windows:\", bad_s)\n",
    "        \n",
    "        tokens = []\n",
    "        bad_words = []\n",
    "        for i, w in enumerate(words):\n",
    "            target_word = target_words[i]\n",
    "            transcribed_word = transcribed_words[i]\n",
    "            if transcribed_word.lower() != target_word.lower():\n",
    "                tokens.append((target_word, 'Target'))\n",
    "                tokens.append((transcribed_word, 'Transcribed'))\n",
    "                tokens.append((\" \",None))\n",
    "                bad_words.append(target_word.lower())\n",
    "                continue\n",
    "            for peak in bad_s:\n",
    "                if w[\"start\"] <= peak and peak <= w[\"end\"]:\n",
    "                    tokens.append((transcribed_word, 'Pronunciation'))\n",
    "                    tokens.append((\" \",None))\n",
    "                    bad_words.append(target_word)\n",
    "                    break\n",
    "            else:\n",
    "                tokens.append((transcribed_word, None))\n",
    "                tokens.append((\" \",None))\n",
    "\n",
    "        print(f\"{len(bad_words)} problematic words collected\")\n",
    "        \n",
    "        yield tokens, gr.Dataset(samples=[[s] for s in bad_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sentence():\n",
    "    global target_sentence, target_words, practice_word\n",
    "    if practice_word == \"\":\n",
    "        practice_word = random.choice(vocab_db)\n",
    "    target_sentence = get_sentences(practice_word)[0]\n",
    "    target_words = get_target_words(target_sentence)\n",
    "    return f\"**Please read aloud the following sentence:**\\n\\n## {target_sentence}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_components(selected_string):\n",
    "    global practice_word\n",
    "    practice_word = selected_string\n",
    "    phonetic, mp3_path = get_pronunciation(selected_string)\n",
    "    print(phonetic, mp3_path)\n",
    "    display_text = f\"{selected_string}: {phonetic}\"\n",
    "    return display_text, mp3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentence = \"This was a curious coincidence.\"\n",
    "target_words = get_target_words(target_sentence)\n",
    "with gr.Blocks() as demo:\n",
    "    markdown = gr.Markdown(f\"**Please read aloud the following sentence:**\\n\\n## {target_sentence}\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            audio = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Record Audio\")\n",
    "            submit_btn = gr.Button(\"Submit\",size='sm')\n",
    "            highlighted = gr.HighlightedText(\n",
    "                label=\"Result\",\n",
    "                combine_adjacent=True,\n",
    "                show_legend=True,\n",
    "                color_map={\n",
    "                    \"Target\": \"green\",\n",
    "                    \"Transcribed\": \"red\",\n",
    "                    \"Pronunciation\": \"yellow\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        with gr.Column(scale=1):\n",
    "            text_input = gr.Textbox(label=\"Cambridge Dictionary\")\n",
    "            audio_component = gr.Audio(label=\"Audio\", type=\"filepath\")\n",
    "            examples = gr.Examples(\n",
    "                examples=[[s] for s in init_examples],\n",
    "                inputs=text_input,\n",
    "                outputs=[text_input, audio_component],\n",
    "                fn=update_components,\n",
    "                run_on_click=True\n",
    "            )\n",
    "            next_btn = gr.ClearButton(components=audio,value='Practice',size='sm')\n",
    "        \n",
    "        submit_btn.click(fn=analyze_audio, inputs=audio, outputs=[highlighted,examples.dataset])\n",
    "        next_btn.click(fn=update_sentence, inputs=[], outputs=[markdown])\n",
    "        \n",
    "        \n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlhlp-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
